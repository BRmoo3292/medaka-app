from fastapi import FastAPI, UploadFile, HTTPException, Request
from fastapi.responses import FileResponse, Response, StreamingResponse
import uvicorn
from fastapi.middleware.cors import CORSMiddleware
from openai import AsyncOpenAI
import time
import numpy as np
import asyncio
from collections import defaultdict, deque
import tempfile
import os
from datetime import datetime
import psycopg2
from psycopg2 import pool
from psycopg2.extras import RealDictCursor
import atexit

# ========================================
# ç’°å¢ƒå¤‰æ•°ãƒ»APIè¨­å®š
# ========================================
DB_URL = os.getenv("DB_URL")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

print(f"[èµ·å‹•æ™‚] DB_URLè¨­å®š: {'ã‚ã‚Š' if DB_URL else 'ãªã—'}")
print(f"[èµ·å‹•æ™‚] OpenAI API: {'è¨­å®šæ¸ˆã¿' if OPENAI_API_KEY else 'æœªè¨­å®š'}")

# ========================================
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«ã®ä½œæˆ
# ========================================
try:
    # SSLè¨­å®šã®è¿½åŠ 
    db_url = DB_URL
    if "pooler.supabase.com" in db_url:
        print("[DBæ¥ç¶š] Supabase Pooleræ¥ç¶šã‚’ä½¿ç”¨")
        if ":5432" in db_url:
            print("[DBæ¥ç¶š] Session Pooler (ãƒãƒ¼ãƒˆ5432)")
        elif ":6543" in db_url:
            print("[DBæ¥ç¶š] Transaction Pooler (ãƒãƒ¼ãƒˆ6543)")
        
        if "sslmode=" not in db_url:
            if "?" in db_url:
                db_url += "&sslmode=require"
            else:
                db_url += "?sslmode=require"
    
    # ğŸ”¥ æ¥ç¶šãƒ—ãƒ¼ãƒ«ã®ä½œæˆ
    pg_pool = psycopg2.pool.SimpleConnectionPool(
        1,   # æœ€å°æ¥ç¶šæ•°
        10,  # æœ€å¤§æ¥ç¶šæ•°
        db_url,
        cursor_factory=RealDictCursor,
        keepalives=1,
        keepalives_idle=30,
        keepalives_interval=10,
        keepalives_count=5,
        connect_timeout=10
    )
    
    if pg_pool:
        print("âœ… [DBæ¥ç¶šãƒ—ãƒ¼ãƒ«] ä½œæˆæˆåŠŸ")
        
        # æ¥ç¶šãƒ†ã‚¹ãƒˆ
        test_conn = pg_pool.getconn()
        test_conn.autocommit = True
        
        with test_conn.cursor() as cur:
            cur.execute("SELECT 1")
            cur.execute("""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public' 
                LIMIT 5;
            """)
            tables = cur.fetchall()
            print(f"[DBæƒ…å ±] æ¤œå‡ºã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«: {[t['table_name'] for t in tables]}")
        
        pg_pool.putconn(test_conn)
        
except Exception as e:
    print(f"âŒ [DBæ¥ç¶šãƒ—ãƒ¼ãƒ«] ä½œæˆå¤±æ•—: {e}")
    exit(1)

# ========================================
# æ¥ç¶šãƒ—ãƒ¼ãƒ«ç®¡ç†é–¢æ•°
# ========================================
def get_db_connection():
    """ãƒ—ãƒ¼ãƒ«ã‹ã‚‰æ¥ç¶šã‚’å–å¾—"""
    try:
        conn = pg_pool.getconn()
        if conn:
            # ğŸ”¥ å¿…ãšautocommitã‚’æœ‰åŠ¹åŒ–
            conn.autocommit = True
            
            # ğŸ”¥ æ¥ç¶šãƒ†ã‚¹ãƒˆ
            try:
                with conn.cursor() as cur:
                    cur.execute("SELECT 1")
                return conn
            except psycopg2.OperationalError:
                # æ¥ç¶šãŒæ­»ã‚“ã§ã„ã‚‹å ´åˆ
                print("âš ï¸ [DBæ¥ç¶š] æ­»ã‚“ã æ¥ç¶šã‚’æ¤œå‡ºã€ç ´æ£„ã—ã¾ã™")
                try:
                    pg_pool.putconn(conn, close=True)  # æ¥ç¶šã‚’ç ´æ£„
                except:
                    pass
                # å†å–å¾—
                conn = pg_pool.getconn()
                conn.autocommit = True
                return conn
                
    except Exception as e:
        print(f"âŒ [DBæ¥ç¶š] å–å¾—å¤±æ•—: {e}")
        return None

def release_db_connection(conn):
    """æ¥ç¶šã‚’ãƒ—ãƒ¼ãƒ«ã«æˆ»ã™"""
    if not conn:
        return
    
    try:
        # æœªã‚³ãƒŸãƒƒãƒˆã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if not conn.closed:
            try:
                if not conn.autocommit:
                    conn.rollback()
            except:
                pass
        
        # ãƒ—ãƒ¼ãƒ«ã«æˆ»ã™
        pg_pool.putconn(conn)
        
    except Exception as e:
        print(f"âš ï¸ [DBæ¥ç¶š] è§£æ”¾ã‚¨ãƒ©ãƒ¼: {e}")

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã«ãƒ—ãƒ¼ãƒ«ã‚’ã‚¯ãƒ­ãƒ¼ã‚º
@atexit.register
def cleanup_pool():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã«ãƒ—ãƒ¼ãƒ«ã‚’ã‚¯ãƒ­ãƒ¼ã‚º"""
    try:
        if pg_pool:
            pg_pool.closeall()
            print("âœ… [DBæ¥ç¶šãƒ—ãƒ¼ãƒ«] ã‚¯ãƒ­ãƒ¼ã‚ºå®Œäº†")
    except:
        pass

# ========================================
# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
# ========================================
active_session = {}
conversation_history = defaultdict(lambda: deque(maxlen=10))
latest_health = "Normal"
proactive_message_counts = defaultdict(int)

class CONFIG:
    PROFILE_ID = 1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

# ========================================
# FastAPIã‚¢ãƒ—ãƒªåˆæœŸåŒ–
# ========================================
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"]  
)

async def get_profile_async(profile_id: int):
    """éåŒæœŸãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, get_profile_sync, profile_id)

def get_profile_sync(profile_id: int):
    """åŒæœŸçš„ã«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
    conn = None
    try:
        conn = get_db_connection()
        if conn is None:
            raise HTTPException(503, "Database connection not available")
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM profiles WHERE id = %s;", (profile_id,))
            profile = cur.fetchone()
            if not profile:
                raise HTTPException(404, "Profile not found")
            return profile
    finally:
        if conn:
            release_db_connection(conn)

def save_conversation_to_db(
    profile_id: int,
    speaker: str,  # 'medaka' ã¾ãŸã¯ å®Ÿéš›ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå
    message: str,
    health_status: str = None,
    development_stage: str = None,
    similar_example_used: bool = False,
    similar_example_text: str = None,
    similarity_score: float = None
):
    """ä¼šè©±å±¥æ­´ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
    conn = None
    try:
        conn = get_db_connection()
        if conn is None:
            print("[ä¼šè©±å±¥æ­´DB] ä¿å­˜ã‚¨ãƒ©ãƒ¼: DBæ¥ç¶šãªã—")
            return None
            
        with conn.cursor() as cur:
            cur.execute("""
                INSERT INTO conversation_history (
                    profile_id, speaker, message, health_status, development_stage,
                    similar_example_used, similar_example_text, similarity_score
                ) VALUES (
                    %s, %s, %s, %s, %s, %s, %s, %s
                ) RETURNING id;
            """, (
                profile_id,
                speaker,
                message,
                health_status,
                development_stage,
                similar_example_used,
                similar_example_text,
                similarity_score
            ))
            
            history_id = cur.fetchone()['id']
            print(f"[ä¼šè©±å±¥æ­´DB] ä¿å­˜å®Œäº† ID: {history_id} ({speaker}: {message[:30]}...)")
            return history_id
            
    except Exception as e:
        print(f"[ä¼šè©±å±¥æ­´DB] ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    finally:
        if conn:
            release_db_connection(conn)
    
@app.get("/best.onnx")
async def serve_onnx_model():
    """ãƒ–ãƒ©ã‚¦ã‚¶æ¤œå‡ºç”¨ã®ONNXãƒ¢ãƒ‡ãƒ«ã‚’é…ä¿¡"""
    model_path = "best.onnx"
    if not os.path.exists(model_path):
        raise HTTPException(404, f"Model file not found: {model_path}")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    with open(model_path, "rb") as f:
        content = f.read()
    
    # Responseã§ç›´æ¥è¿”ã™ï¼ˆCORSãƒ˜ãƒƒãƒ€ãƒ¼å®Œå…¨åˆ¶å¾¡ï¼‰
    return Response(
        content=content,
        media_type="application/octet-stream",
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET, OPTIONS",
            "Access-Control-Allow-Headers": "*",
            "Access-Control-Expose-Headers": "*",
            "Cache-Control": "public, max-age=31536000",
            "Content-Type": "application/octet-stream",
            "Content-Length": str(len(content))
        }
    )
@app.options("/best.onnx")
async def options_onnx_model():
    return Response(
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET, OPTIONS",
            "Access-Control-Allow-Headers": "*"
        }
    )

@app.post("/transcribe_audio")
async def transcribe_audio(file: UploadFile):
    """GPT-4o-mini-transcribeã§éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ï¼ˆé«˜é€Ÿç‰ˆï¼‰"""
    start = time.time()
    audio_content = await file.read()
    with tempfile.NamedTemporaryFile(delete=False, suffix=".webm") as temp_audio:
            temp_audio.write(audio_content)
            temp_audio_path = temp_audio.name
    with open(temp_audio_path, "rb") as audio_file:
            transcript = await openai_client.audio.transcriptions.create(
                model="gpt-4o-mini-transcribe",
                file=audio_file,
                language="ja",
                response_format="text"  # ğŸ†• textã«å¤‰æ›´ï¼ˆã‚ˆã‚Šé«˜é€Ÿï¼‰
            )
    os.unlink(temp_audio_path)
        # textã®å ´åˆã€transcriptã¯æ–‡å­—åˆ—ã§è¿”ã£ã¦ãã‚‹
    return {
            "text": transcript,  # ç›´æ¥æ–‡å­—åˆ—
            "duration": None,
            "language": "ja"
        }

# assess_child_expression_level é–¢æ•°ã‚’è¿½åŠ 
async def assess_child_expression_level(child_input: str, current_stage: str) -> dict:
    """
    å…ç«¥ã®ç™ºè©±ã‹ã‚‰è‡ªå·±è¡¨ç¾ãƒ¬ãƒ™ãƒ«ã‚’åˆ¤å®šï¼ˆLLMä½¿ç”¨ï¼‰
    
    Returns:
        {
            'detected_stage': 'stage_1' | 'stage_2' | 'stage_3',
            'confidence': 0.0-1.0,
            'reasoning': 'åˆ¤å®šç†ç”±',
            'should_upgrade': True | False
        }
    """
    # ç™ºé”æ®µéšã®å®šç¾©
    stage_definitions = {
        'stage_1': """
ã€Stage 1: å˜èªãƒ»æœ€å°é™ã®å¿œç­”ãƒ¬ãƒ™ãƒ«ã€‘
ï¼œç™ºè©±ã®ç‰¹å¾´ï¼
-å¿œç­”ãŒ å˜èªã‚„ã”ãçŸ­ã„æ–‡ã®ã¿
-ä¼šè©±ã‚’ è‡ªç™ºçš„ã«å§‹ã‚ã‚‹ã“ã¨ãŒã§ããªã„
-ç›¸æ‰‹ã«è©±ã—ã‹ã‘ã‚‰ã‚Œã¦ã‚‚ã€è¿”ç­”ã§ãã‚‹ã®ã¯é™ã‚‰ã‚ŒãŸå ´é¢ã ã‘
-è¨€è‘‰ãŒå‡ºãªã„ã“ã¨ã‚„ã‚ªã‚¦ãƒ è¿”ã—ãŒå¤šã„
-è©±ã‚’åºƒã’ãŸã‚Šè³ªå•ã‚’è¿”ã—ãŸã‚Šã¯é›£ã—ã„
""",
        'stage_2': """
ã€Stage 2: çŸ­æ–‡ãƒ»æ–­ç‰‡çš„ãªå¿œç­”ãƒ¬ãƒ™ãƒ«ã€‘
-è©±é¡Œã‚’åºƒã’ã‚‹ãƒ»èˆˆå‘³ã‚’å…±æœ‰ã™ã‚‹ã“ã¨ãŒé›£ã—ã„
-å¿œç­”ãŒçŸ­ã„ã€æ›–æ˜§ãªè¿”äº‹ãŒå¤šã„
-ã‚„ã‚Šå–ã‚Šã®ãƒ†ãƒ³ãƒãŒé…ã‚Œã‚‹ãƒ»ã‚ºãƒ¬ã‚‹ã“ã¨ãŒã‚ã‚‹
-ã€Œãƒ¡ãƒ€ã‚«5åŒ¹ã„ã‚‹ã€ã€Œé€Ÿã„ã­ã€æ–°å¹¹ç·šã¿ãŸã„ã€ãªã©çŸ­æ–‡ã§è¿”ã›ã‚‹
-ã€Œã‹ãªã€ã€ŒãŸã¶ã‚“ã€ãªã©æ›–æ˜§ãªè¿”äº‹ã§ã‚„ã‚Šå–ã‚ŠãŒæ­¢ã¾ã‚‹
""",
        'stage_3': """
ã€Stage 3: æ–‡ç« ãƒ»ä¸€æ–¹çš„ãªèª¬æ˜ãƒ¬ãƒ™ãƒ«ã€‘
-ä¼šè©±è‡ªä½“ã¯æˆç«‹ã™ã‚‹ãŒã€ä¸€æ–¹çš„ã«ãªã‚Šã‚„ã™ã„
-ç›¸æ‰‹ã®ç™ºè¨€ã«å¿œç­”ã§ããšã€ã‚­ãƒ£ãƒƒãƒãƒœãƒ¼ãƒ«ãŒé€”åˆ‡ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹
-ä¼šè©±ã®é †ç•ªãŒå®ˆã‚Œãªã„ï¼ç›¸æ‰‹ã®æ°—æŒã¡ã‚’æ±²ã‚ãªã„
-å‹é”é–¢ä¿‚ã‚’ç¯‰ãã®ãŒé›£ã—ã„
-è«–ç†çš„ã§é•·ã„èª¬æ˜ã‚’ã™ã‚‹ãŒã€ç›¸æ‰‹ã®èˆˆå‘³ã«åˆã‚ãªã„
-ç›¸æ‰‹ã®è¿”ç­”ã‚’æ‹¾ã‚ãšã€è‡ªåˆ†ã®è©±ã‚’ç¶šã‘ã¦ã—ã¾ã†
-è¡¨é¢ä¸Šã¯ä¼šè©±ã§ãã¦ã„ã‚‹ãŒã€å™›ã¿åˆã‚ãªã„ã“ã¨ãŒå¤šã„
"""
    }
    
    prompt = f"""
ã‚ãªãŸã¯å…ç«¥ã®è¨€èªç™ºé”ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ç™ºè©±ã‚’åˆ†æã—ã€è‡ªå·±è¡¨ç¾ãƒ¬ãƒ™ãƒ«ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚
ã€ç™ºé”æ®µéšã®å®šç¾©ã€‘
{stage_definitions['stage_1']}
{stage_definitions['stage_2']}
{stage_definitions['stage_3']}
ã€ç¾åœ¨ã®ç™»éŒ²æ®µéšã€‘
{current_stage}
ã€å…ç«¥ã®ç™ºè©±ã€‘
ã€Œ{child_input}ã€
ã€åˆ¤å®šæ‰‹é †ã€‘
1. ç™ºè©±ã®å†…å®¹ãƒ»æ„å›³ã‚’ç¢ºèªï¼ˆä½•ã‚’ä¼ãˆã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã‹ï¼‰
2. ä¼šè©±çš„ãªè¦ç´ ã‚’ç¢ºèªï¼ˆèˆˆå‘³å…±æœ‰ãƒ»è³ªå•ãƒ»åŒæ„ãªã©ï¼‰
3. ç™ºè©±ã®é•·ã•ã‚’ç¢ºèªï¼ˆå˜èªæ•°ãƒ»æ–‡ã®æ•°ï¼‰
4. è‡ªç™ºæ€§ã‚’ç¢ºèª

**é‡è¦**: æ–‡æ³•ã®æ­£ç¢ºã•ã‚ˆã‚Šã€ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ„å›³ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚
- ã€Œä»Šæ—¥ã®å¤©æ°—ã‚ã£ã¡ã‚ƒã„ã„ã­ã€â†’ èˆˆå‘³å…±æœ‰ã‚ã‚Š â†’ stage_2
- ã€Œã†ã‚“ã€ã€Œãã†ã€â†’ æœ€å°é™å¿œç­” â†’ stage_1


ä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

{{
  "detected_stage": "stage_1",
  "confidence": 0.85,
  "reasoning": "å˜èªã®ã¿ã§æ–‡æ§‹é€ ãŒãªã„ãŸã‚",
  "word_count": 3
}}

**JSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚**
"""
    
    try:
        # Geminiå‘¼ã³å‡ºã—ã‚’å‰Šé™¤ã—ã€OpenAI APIã«ç½®ãæ›ãˆ
        response = await openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯å…ç«¥ã®è¨€èªç™ºé”ã®å°‚é–€å®¶ã§ã™ã€‚æŒ‡ç¤ºã«å¾“ã£ã¦JSONå½¢å¼ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=200
        )
        # JSONã‚’ãƒ‘ãƒ¼ã‚¹
        import json
        response_text = response.choices[0].message.content.strip()
        response_text = response_text.replace('```json\n', '').replace('```\n', '').replace('```', '').strip()
        result = json.loads(response_text)
        
        # ğŸ”¥ 1æ®µéšæ˜‡æ ¼ã®ã¿è¨±å¯ï¼ˆé£›ã³ç´šãªã—ï¼‰
        stage_order = {'stage_1': 1, 'stage_2': 2, 'stage_3': 3}
        current_level = stage_order.get(current_stage, 1)
        detected_level = stage_order.get(result['detected_stage'], 1)
        
        # æ˜‡æ ¼åˆ¤å®šï¼ˆ1æ®µéšã®ã¿ï¼‰
        if detected_level == current_level + 1:
            result['should_upgrade'] = True
            print(f"âœ… [ç™ºè©±ãƒ¬ãƒ™ãƒ«åˆ¤å®š] 1æ®µéšæ˜‡æ ¼ã‚’æ¨å¥¨: {current_stage} â†’ {result['detected_stage']}")
        elif detected_level > current_level + 1:
            # é£›ã³ç´šã¯è¨±å¯ã—ãªã„
            result['should_upgrade'] = False
            print(f"âš ï¸ [ç™ºè©±ãƒ¬ãƒ™ãƒ«åˆ¤å®š] é£›ã³ç´šã¯ä¸å¯: {current_stage} â†’ {result['detected_stage']}")
        else:
            result['should_upgrade'] = False
            print(f"[ç™ºè©±ãƒ¬ãƒ™ãƒ«åˆ¤å®š] æ˜‡æ ¼ãªã—: æ¤œå‡º={result['detected_stage']}, ç¾åœ¨={current_stage}")
        
        print(f"[ç™ºè©±ãƒ¬ãƒ™ãƒ«åˆ¤å®š] ä¿¡é ¼åº¦: {result['confidence']:.2f}")
        print(f"[ç™ºè©±ãƒ¬ãƒ™ãƒ«åˆ¤å®š] ç†ç”±: {result['reasoning']}")
        return result
        
    except json.JSONDecodeError as e:
        print(f"âš ï¸ [ç™ºè©±ãƒ¬ãƒ™ãƒ«åˆ¤å®š] JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")
        return {
            'detected_stage': current_stage,
            'confidence': 0.0,
            'reasoning': 'JSONè§£æã‚¨ãƒ©ãƒ¼',
            'should_upgrade': False
        }
    except Exception as e:
        print(f"âŒ [ç™ºè©±ãƒ¬ãƒ™ãƒ«åˆ¤å®š] ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            'detected_stage': current_stage,
            'confidence': 0.0,
            'reasoning': 'ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ',
            'should_upgrade': False
        }

@app.post("/talk_with_fish_text")
async def talk_with_fish_text(file: UploadFile):
    start_total = time.time()
    time_log = {}
    
    # â±ï¸ 1. éŸ³å£°èªè­˜ï¼ˆå…ˆã«å®Ÿè¡Œï¼‰
    t1 = time.time()
    transcription_result = await transcribe_audio(file)
    user_input = transcription_result["text"]
    t2 = time.time()
    time_log['01_éŸ³å£°èªè­˜'] = t2 - t1
    print(f"[â±ï¸ éŸ³å£°èªè­˜] {time_log['01_éŸ³å£°èªè­˜']:.2f}ç§’")
    
    # â±ï¸ 2. ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
    t1 = time.time()
    profile = await get_profile_async(CONFIG.PROFILE_ID)
    current_stage = profile["development_stage"]
    child_name = profile["name"]
    t2 = time.time()
    time_log['02_ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—'] = t2 - t1
    print(f"[â±ï¸ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—] {time_log['02_ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—']:.2f}ç§’")
    
    print(f"å…ç«¥ã®ç™ºè©±:{user_input}")
    save_conversation_to_db(
        profile_id=CONFIG.PROFILE_ID,
        speaker=child_name,  # ğŸ”¥ 'child'ã§ã¯ãªãå®Ÿéš›ã®åå‰
        message=user_input,
        health_status=latest_health,
        development_stage=current_stage
    )
    # â±ï¸ 2. ä¼šè©±å±¥æ­´ã®åˆæœŸåŒ–
    t1 = time.time()
    if CONFIG.PROFILE_ID not in conversation_history:
        conversation_history[CONFIG.PROFILE_ID] = []
    current_history = conversation_history[CONFIG.PROFILE_ID]
    session = active_session.get(CONFIG.PROFILE_ID)
    t2 = time.time()
    time_log['02_å±¥æ­´åˆæœŸåŒ–'] = t2 - t1
    print(f"[â±ï¸ å±¥æ­´åˆæœŸåŒ–] {time_log['02_å±¥æ­´åˆæœŸåŒ–']:.2f}ç§’")
    
    assessment_result = None  
    similar_example = None
    expression_assessment = None
    use_similar_example = False 

    if session is None:
        print("[ä¼šè©±ãƒ•ãƒ­ãƒ¼] 1å›ç›®ã®ä¼šè©± - é¡ä¼¼ä¾‹ã‚’æ¤œç´¢")
        
        # â±ï¸ 3. ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
        t1 = time.time()
        similar_example = await find_similar_conversation(user_input, current_stage)
        t2 = time.time()
        time_log['03_ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢'] = t2 - t1
        print(f"[â±ï¸ ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢] {time_log['03_ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢']:.2f}ç§’")
        
        # ğŸ”¥ é¡ä¼¼åº¦ã®é–¾å€¤åˆ¤å®šï¼ˆçµ±ä¸€ã•ã‚ŒãŸåŸºæº–ï¼‰
        SIMILARITY_THRESHOLD = 0.88  # ã“ã®å€¤ã‚ˆã‚Šå°ã•ã„ = é¡ä¼¼åº¦ãŒé«˜ã„
        
        if similar_example is None:
            print("[ä¼šè©±ãƒ•ãƒ­ãƒ¼] é¡ä¼¼ä¾‹ãªã— - ç™ºè©±ãƒ¬ãƒ™ãƒ«åˆ¤å®šã‚’å®Ÿè¡Œ")
            use_similar_example = False
        else:
            print(f"[ä¼šè©±ãƒ•ãƒ­ãƒ¼] é¡ä¼¼åº¦ãŒé«˜ã„ ({similar_example['distance']:.4f} < {SIMILARITY_THRESHOLD}) - é¡ä¼¼ä¾‹ã‚’ä½¿ç”¨")
            use_similar_example = True
        
        if not use_similar_example:
            print("[ä¼šè©±ãƒ•ãƒ­ãƒ¼] ç™ºè©±ãƒ¬ãƒ™ãƒ«åˆ¤å®š+å¿œç­”ç”Ÿæˆã‚’ä¸¦åˆ—å®Ÿè¡Œ")
            t1 = time.time()
        
            expression_assessment, reply_text = await asyncio.gather(
                assess_child_expression_level(user_input, current_stage),
                get_medaka_reply(
                    user_input, 
                    latest_health, 
                    current_history, 
                    None,
                    profile
                )
            )
            
            t2 = time.time()
            time_log['03_ç™ºè©±ãƒ¬ãƒ™ãƒ«åˆ¤å®š+å¿œç­”ç”Ÿæˆ'] = t2 - t1
            print(f"[â±ï¸ ç™ºè©±ãƒ¬ãƒ™ãƒ«åˆ¤å®š+å¿œç­”ç”Ÿæˆï¼ˆä¸¦åˆ—ï¼‰] {time_log['03_ç™ºè©±ãƒ¬ãƒ™ãƒ«åˆ¤å®š+å¿œç­”ç”Ÿæˆ']:.2f}ç§’")
            save_conversation_to_db(
                profile_id=CONFIG.PROFILE_ID,
                speaker='medaka',  # ãƒ¡ãƒ€ã‚«ã¯å›ºå®š
                message=reply_text,
                health_status=latest_health,
                development_stage=current_stage,
                similar_example_used=False,
                similar_example_text=None,
                similarity_score=None
            )
            # ğŸ”¥ æ˜‡æ ¼åˆ¤å®šï¼ˆä¿¡é ¼åº¦0.7ä»¥ä¸Š ã‹ã¤ 1æ®µéšæ˜‡æ ¼æ¨å¥¨ï¼‰
            if expression_assessment['should_upgrade'] and expression_assessment['confidence'] >= 0.7:
                t3 = time.time()
                upgrade_result = await upgrade_by_expression_assessment_async(
                    CONFIG.PROFILE_ID,
                    current_stage,
                    expression_assessment['reasoning']
                )
                t4 = time.time()
                time_log['03_æ®µéšæ›´æ–°'] = t4 - t3
                print(f"[â±ï¸ æ®µéšæ›´æ–°] {time_log['03_æ®µéšæ›´æ–°']:.2f}ç§’")
                
                if upgrade_result['success']:
                    profile['development_stage'] = upgrade_result['new_stage']
                    current_stage = upgrade_result['new_stage']
                    print(f"âœ… [æ®µéšå¤‰æ›´] {upgrade_result['old_stage']} â†’ {upgrade_result['new_stage']}")
            else:
                if expression_assessment.get('confidence', 0) < 0.7:
                    print(f"[æ®µéšå¤‰æ›´] ã‚¹ã‚­ãƒƒãƒ— - ä¿¡é ¼åº¦ä¸è¶³ ({expression_assessment.get('confidence', 0):.2f})")
                else:
                    print(f"[æ®µéšå¤‰æ›´] ã‚¹ã‚­ãƒƒãƒ— - æ˜‡æ ¼æ¡ä»¶ã‚’æº€ãŸã•ãªã„")
        
        else:
            # ğŸ”¥ é¡ä¼¼ä¾‹ã‚’ä½¿ã†å ´åˆï¼ˆæ—¢å­˜ã®å‡¦ç†ï¼‰
            print("[ä¼šè©±ãƒ•ãƒ­ãƒ¼] é¡ä¼¼ä¾‹ã‚’ä½¿ç”¨ã—ãŸå¿œç­”ç”Ÿæˆ")
            t1 = time.time()
            reply_text = await get_medaka_reply(
                user_input, 
                latest_health, 
                current_history, 
                similar_example,  # é¡ä¼¼ä¾‹ã‚’æ¸¡ã™
                profile
            )
            t2 = time.time()
            time_log['04_å¿œç­”ç”Ÿæˆ'] = t2 - t1
            print(f"[â±ï¸ å¿œç­”ç”Ÿæˆ] {time_log['04_å¿œç­”ç”Ÿæˆ']:.2f}ç§’")
            save_conversation_to_db(
                profile_id=CONFIG.PROFILE_ID,
                speaker='medaka',  # ãƒ¡ãƒ€ã‚«ã¯å›ºå®š
                message=reply_text,
                health_status=latest_health,
                development_stage=current_stage,
                similar_example_used=True,
                similar_example_text=similar_example['text'],
                similarity_score=similar_example['distance']
            )
        # â±ï¸ 5. ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
        t1 = time.time()
        is_max_stage = current_stage == "stage_3"
        
        if is_max_stage:
            print(f"[ã‚»ãƒƒã‚·ãƒ§ãƒ³] æœ€é«˜æ®µéš {current_stage} - åˆ¤å®šã‚¹ã‚­ãƒƒãƒ—")
        elif (use_similar_example and
            similar_example and 
            'child_reply_1_embedding' in similar_example and 
            'child_reply_2_embedding' in similar_example and 
            similar_example.get('child_reply_2_embedding') is not None):
            
            session = ConversationSession(
                profile_id=CONFIG.PROFILE_ID,
                child_name=child_name,  # ğŸ”¥ è¿½åŠ 
                first_input=user_input,
                medaka_response=reply_text,
                similar_example=similar_example,
                current_stage=current_stage
            )
            active_session[CONFIG.PROFILE_ID] = session
            print(f"[ã‚»ãƒƒã‚·ãƒ§ãƒ³] ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆå®Œäº† - æ¬¡å›åˆ¤å®šå®Ÿè¡Œäºˆå®šï¼ˆé¡ä¼¼åº¦: {similar_example['distance']:.4f}ï¼‰")
        else:
            print(f"[ã‚»ãƒƒã‚·ãƒ§ãƒ³] é€šå¸¸ã®ä¼šè©±ã¨ã—ã¦å‡¦ç†")
        
        t2 = time.time()
        time_log['05_ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ'] = t2 - t1
        print(f"[â±ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ] {time_log['05_ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ']:.2f}ç§’")   
    else:
        # 2å›ç›®ã®ä¼šè©±ï¼ˆæ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰
        print("[ä¼šè©±ãƒ•ãƒ­ãƒ¼] 2å›ç›®ã®ä¼šè©± - ç™ºé”æ®µéšåˆ¤å®šã‚’å®Ÿè¡Œ")
        
        # â±ï¸ 3. ç™ºé”æ®µéšåˆ¤å®š
        t1 = time.time()
        assessment = await classify_child_response(
            user_input,
            session.similar_example,
            openai_client,
        )
        t2 = time.time()
        time_log['03_ç™ºé”æ®µéšåˆ¤å®š'] = t2 - t1
        print(f"[â±ï¸ ç™ºé”æ®µéšåˆ¤å®š] {time_log['03_ç™ºé”æ®µéšåˆ¤å®š']:.2f}ç§’")
        
        # â±ï¸ 4. åˆ¤å®šçµæœå‡¦ç†
        t1 = time.time()
        assessment_result = {
            'result': assessment[0],
            'maintain_score': round(float(assessment[1]), 3),
            'upgrade_score': round(float(assessment[2]), 3),
            'confidence_score': round(float(abs(assessment[2] - assessment[1])), 5),
            'assessed_at': datetime.now(),
        }
        
        if assessment[0] == "æ˜‡æ ¼":
            new_stage = upgrade_development_stage(CONFIG.PROFILE_ID, current_stage)
            profile["development_stage"] = new_stage
            
            if new_stage != current_stage:
                assessment_result['stage_upgraded'] = True
                assessment_result['previous_stage'] = current_stage
                assessment_result['new_stage'] = new_stage
                print(f"[ä¼šè©±ãƒ•ãƒ­ãƒ¼] ğŸ‰ ç™ºé”æ®µéšãŒæ˜‡æ ¼ã—ã¾ã—ãŸï¼ {current_stage} â†’ {new_stage}")
            else:
                assessment_result['stage_upgraded'] = False
                assessment_result['already_max'] = True
                print(f"[ä¼šè©±ãƒ•ãƒ­ãƒ¼] ã™ã§ã«æœ€é«˜æ®µéš {current_stage} ã«åˆ°é”ã—ã¦ã„ã¾ã™")
        else:
            assessment_result['stage_upgraded'] = False
            print(f"[ä¼šè©±ãƒ•ãƒ­ãƒ¼] ç¾çŠ¶ç¶­æŒ - {current_stage} ã®ã¾ã¾")
        t2 = time.time()
        time_log['04_åˆ¤å®šçµæœå‡¦ç†'] = t2 - t1
        print(f"[â±ï¸ åˆ¤å®šçµæœå‡¦ç†] {time_log['04_åˆ¤å®šçµæœå‡¦ç†']:.2f}ç§’")
        
        # â±ï¸ 5. ãƒ¡ãƒ€ã‚«å¿œç­”ç”Ÿæˆ
        t1 = time.time()
        reply_text = await get_medaka_reply(user_input, latest_health, current_history, None, profile)
        t2 = time.time()
        time_log['05_å¿œç­”ç”Ÿæˆ'] = t2 - t1
        print(f"[â±ï¸ å¿œç­”ç”Ÿæˆ] {time_log['05_å¿œç­”ç”Ÿæˆ']:.2f}ç§’")
        save_conversation_to_db(
            profile_id=CONFIG.PROFILE_ID,
            speaker='medaka',  # ãƒ¡ãƒ€ã‚«ã¯å›ºå®š
            message=reply_text,
            health_status=latest_health,
            development_stage=current_stage,
            similar_example_used=False
        )
        # â±ï¸ 6. ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†å‡¦ç†
        t1 = time.time()
        del active_session[CONFIG.PROFILE_ID]
        t2 = time.time()
        time_log['06_ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†'] = t2 - t1
        print(f"[â±ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†] {time_log['06_ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†']:.2f}ç§’")

    # â±ï¸ 7. ä¼šè©±å±¥æ­´ä¿å­˜
    t1 = time.time()
    conversation_entry = {
            "child": user_input,
            "medaka": reply_text,
            "timestamp": datetime.now(),
            "similar_example_used": similar_example['text'] if similar_example else None,
            "similarity_score": similar_example['distance'] if similar_example else None,
            "has_assessment": assessment_result is not None,
            "assessment_result": assessment_result,
            "session_status": "started" if session and CONFIG.PROFILE_ID in active_session else "completed"
    }
    conversation_history[CONFIG.PROFILE_ID].append(conversation_entry)
    if len(conversation_history[CONFIG.PROFILE_ID]) > 20:
        conversation_history[CONFIG.PROFILE_ID] = conversation_history[CONFIG.PROFILE_ID][-20:]

    print(f"[ä¼šè©±å±¥æ­´] ç¾åœ¨ã®å±¥æ­´ä»¶æ•°: {len(conversation_history[CONFIG.PROFILE_ID])}")
    t2 = time.time()
    time_log['07_å±¥æ­´ä¿å­˜'] = t2 - t1
    print(f"[â±ï¸ å±¥æ­´ä¿å­˜] {time_log['07_å±¥æ­´ä¿å­˜']:.2f}ç§’")
    
    # â±ï¸ 8. TTSæº–å‚™ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹ã¾ã§ï¼‰
    t_stream_start = time.time()
    
    async def audio_stream():
        chunk_count = 0
        t_first_chunk = None
        
        async with openai_client.audio.speech.with_streaming_response.create(
            model="tts-1",
            voice="nova",
            instructions="Voice Affect:ã‹ã‚ã„ã‚‰ã—ã„, Tone:é«˜ã„, Pacing:ã‚†ã£ãã‚Š",
            speed=1.0,
            input=reply_text,
            response_format="mp3",
        ) as response:
            async for chunk in response.iter_bytes():
                chunk_count += 1
                if chunk_count == 1:
                    t_first_chunk = time.time()
                    first_chunk_time = t_first_chunk - t_stream_start
                    print(f"[â±ï¸ TTSæœ€åˆã®ãƒãƒ£ãƒ³ã‚¯] {first_chunk_time:.2f}ç§’")
                yield chunk
    
    # â±ï¸ ç·å‡¦ç†æ™‚é–“ã®è¨ˆç®—ã¨è¡¨ç¤º
    end_total = time.time()
    total_time = end_total - start_total
    
    print("\n" + "="*50)
    print("â±ï¸  å‡¦ç†æ™‚é–“ã®è©³ç´°")
    print("="*50)
    
    for key in sorted(time_log.keys()):
        duration = time_log[key]
        percentage = (duration / total_time) * 100
        bar_length = int(percentage / 2)
        bar = "â–ˆ" * bar_length + "â–‘" * (50 - bar_length)
        print(f"{key:20} â”‚ {bar} â”‚ {duration:6.2f}ç§’ ({percentage:5.1f}%)")
    
    print("-" * 50)
    print(f"{'åˆè¨ˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹ã¾ã§ï¼‰':20} â”‚ {total_time:6.2f}ç§’ (100.0%)")
    print("="*50 + "\n")
    
    return StreamingResponse(
            audio_stream(),
            media_type="audio/mpeg",
            headers={"Content-Disposition": "inline; filename=reply.mp3"}
        )

async def generate_tts(text: str) -> str:
    """TTSç”Ÿæˆï¼ˆéåŒæœŸé–¢æ•°ï¼‰"""
    async with openai_client.audio.speech.with_streaming_response.create(
        model="tts-1",
        voice="nova",
        instructions="Voice Affect:ã‹ã‚ã„ã‚‰ã—ã„, Tone:é«˜ã„, Pacing:ã‚†ã£ãã‚Š",
        speed=1.0,
        input=text,
        response_format="mp3",
    ) as response:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tts_file:
            async for chunk in response.iter_bytes():
                tts_file.write(chunk)
            return tts_file.name

async def find_similar_conversation(user_input: str, development_stage: str, similarity_threshold: float = 0.88):
    resp = await openai_client.embeddings.create(
        input=[user_input],
        model="text-embedding-3-small"
    )
    query_vector = resp.data[0].embedding
    
    conn = None
    try:
        conn = get_db_connection()
        if conn is None:
            print("[é¡ä¼¼ä¼šè©±] DBæ¥ç¶šãªã—")
            return None

        with conn.cursor() as cur:
            cur.execute("""
                SELECT text, fish_text, children_reply_1, children_reply_2,
                       child_reply_1_embedding, child_reply_2_embedding,
                       user_embedding <-> %s::vector as distance
                FROM conversations
                WHERE development_stage = %s
                ORDER BY distance
                LIMIT 1;
            """, (query_vector, development_stage))
            
            result = cur.fetchone()
            if not result:
                print("[é¡ä¼¼ä¼šè©±] é¡ä¼¼ä¾‹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return None

            print(f"[é¡ä¼¼æ¤œç´¢] è¦‹ã¤ã‹ã£ãŸä¾‹: '{result['text']}'")
            print(f"[é¡ä¼¼æ¤œç´¢] é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {result['distance']:.4f}")
            if result['distance'] < similarity_threshold:
                print("[é¡ä¼¼ä¼šè©±] é¡ä¼¼ä¾‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:", result['text'] )
                return result
            else:
                print("[é¡ä¼¼ä¼šè©±] é¡ä¼¼ä¾‹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return None
    except Exception as e:
        print(f"âŒ [é¡ä¼¼æ¤œç´¢] ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    finally:
        if conn:
            release_db_connection(conn)
        
async def get_medaka_reply(user_input, health_status="ä¸æ˜", conversation_hist=None, similar_example=None, profile_info=None):
    start = time.time()
    
    if health_status == "Active":
        medaka_state = "å…ƒæ°—"
    elif health_status == "Normal":
        medaka_state = "ä¼‘æ†©ä¸­"
    elif health_status == "Lethargic":
        medaka_state = "å…ƒæ°—ãªã„"
    else:
        medaka_state = "ä¼‘æ†©ä¸­"
    
    print("ãƒ¡ãƒ€ã‚«ã®çŠ¶æ…‹:", medaka_state)
    
    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®å–å¾—
    if profile_info:
        profile_name = profile_info.get('name', 'Unknown')
        age_text = f"{profile_info['age']}æ­³" if profile_info.get('age') else "å¹´é½¢ä¸æ˜"
        stage_text = profile_info.get('development_stage', 'ä¸æ˜')
        profile_context = f"è©±ã—ç›¸æ‰‹: {profile_name}ã•ã‚“ ({age_text}, {stage_text})\n"
        
        # ä¼šè©±å±¥æ­´
        history_context = ""
        if conversation_hist and len(conversation_hist) > 0:
            recent_history = conversation_hist[-3:]  # æœ€æ–°3ä»¶
            history_context = "æœ€è¿‘ã®ä¼šè©±å±¥æ­´:\n"
            for i, h in enumerate(recent_history, 1):
                # ğŸ”¥ child ãŒ None ã®å ´åˆï¼ˆãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰ã¯ã‚¹ã‚­ãƒƒãƒ—
                if h['child'] is None:
                    history_context += f"{i}. ãƒ¡ãƒ€ã‚«ã€Œ{h['medaka']}ã€\n"
                else:
                    history_context += f"{i}. å…ç«¥ã€Œ{h['child']}ã€â†’ ãƒ¡ãƒ€ã‚«ã€Œ{h['medaka']}ã€\n"
        history_context += "\n"
        
        # ğŸ†• è‡ªå·±è¡¨ç¾ãƒ¬ãƒ™ãƒ«ã®å–å¾—
        stage = profile_info.get('development_stage', 'stage_1')
        
        # stage ã‹ã‚‰æ•°å€¤ã‚’æŠ½å‡º
        if stage == 'stage_1':
            child_expression_level = 1
        elif stage == 'stage_2':
            child_expression_level = 2
        elif stage == 'stage_3':
            child_expression_level = 3
        else:
            child_expression_level = 1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    else:
        profile_context = ""
        history_context = ""
        child_expression_level = 1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    # ğŸ†• è‡ªå·±è¡¨ç¾ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸå¿œç­”æˆ¦ç•¥
    if child_expression_level == 1:
        response_strategy = """
ã€å¿œç­”æˆ¦ç•¥ã€‘
å…ç«¥ã®ç™ºè©±ãŒã€ŒæŠ½è±¡çš„ã€ã‹ã€Œå…·ä½“çš„ã€ã‹ã‚’åˆ¤æ–­ã—ã€ä½¿ã„åˆ†ã‘ã¦ãã ã•ã„ã€‚
**ç™ºè©±ãŒæŠ½è±¡çš„ãªå ´åˆ**: å¿…ãš2æŠã‚„ã€Œã©ã£ã¡ï¼Ÿã€ã§ç­”ãˆã‚’å¼•ãå‡ºã™ã‹ã€å…ç«¥ã®å˜èªã«è¿½åŠ ã®è¨€è‘‰ã‚’ã¤ã‘ã¦èª˜å°ã™ã‚‹ã€‚
**ç™ºè©±ãŒå…·ä½“çš„ãªå ´åˆ**: å…ç«¥ã®å˜èªã‚’çŸ­æ–‡ã«ç›´ã—ã¦è¿”ã™ã€‚ã¾ãŸã¯ã€ç™ºè©±ã‚’ãã®ã¾ã¾è‚¯å®šã—ã¤ã¤ã€æ„Ÿæƒ…è¡¨ç¾ã‚„èªå½™ã‚’å°‘ã—å¢—ã‚„ã™ï¼ˆä¾‹ï¼šã€Œãã‚Œã„ã€â†’ã€Œãã‚Œã„ã ã­ã€œï¼ãƒ”ã‚«ãƒ”ã‚«ã—ã¦ã¦ã†ã‚Œã—ã„ã­ã€ï¼‰ã€‚
"""
    elif child_expression_level == 2:
        response_strategy = """
ã€å¿œç­”æˆ¦ç•¥ã€‘
å…ç«¥ã®ç™ºè©±ã‚¿ã‚¤ãƒ—ã«åˆã‚ã›ã¦å¯¾å¿œã‚’å¤‰ãˆã¦ãã ã•ã„ã€‚
- **å˜èªã‚„çŸ­ã„ãƒ•ãƒ¬ãƒ¼ã‚ºã©ã¾ã‚Š**: çŸ­ã„è¿”ç­”ã‚’ç¹°ã‚Šè¿”ã—ãªãŒã‚‰ã€ã€Œã©ã†ã—ã¦ï¼Ÿã€ã€Œã©ã‚“ãªï¼Ÿã€ã€Œä»–ã«ã¯ï¼Ÿã€ã¨è³ªå•ã‚’è¶³ã™ã€‚ã¾ãŸã¯èˆˆå‘³ã«æ²¿ã£ã¦ã€Œã‚‚ã£ã¨è©³ã—ãæ•™ãˆã¦ã€ã¨æ˜ã‚Šä¸‹ã’ã‚‹ã€‚
- **è©±ãŒå˜ç™ºçš„ã§é †åºãŒãªã„**: ã€Œã¾ãšã¯ï¼Ÿã€ã€Œæ¬¡ã¯ï¼Ÿã€ãªã©ã€ç†ç”±ã¥ã‘ã‚„é †åºç«‹ã¦ã‚’ä¿ƒã™ã€‚
- **èªå½™ã‚„æ–‡æ³•ãŒä¸è‡ªç„¶ã§ã€æ–‡è„ˆãŒã‚ºãƒ¬ã¦ã„ã‚‹**: å°‘ã—ã‚ºãƒ¬ãŸèª¬æ˜ã‚„ä¸€æ–¹çš„ãªè©±ã§ã‚‚å¦å®šã›ãšã«èãå½¹ã«ãªã‚‹ã€‚
"""
    else:
        # stage_3 ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        response_strategy = ""
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
    if similar_example:
        prompt = f"""
ã‚ãªãŸã¯æ°´æ§½ã«ä½ã‚€ã‹ã‚ã„ã„ãƒ¡ãƒ€ã‚«ã€Œã‚·ãƒ­ã¡ã‚ƒã‚“ã€ã§ã™ã€‚
ãƒ¡ãƒ€ã‚«ã®çŠ¶æ…‹: {medaka_state}
{profile_context}
ä»¥ä¸‹ã®ä¾‹ã¨å…¨ãåŒã˜è¨€è‘‰ã§30å­—ç¨‹åº¦ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚
ã€ä¼šè©±ã€‘
å…ç«¥:ã€Œ{similar_example['text']}ã€
ãƒ¡ãƒ€ã‚«:ã€Œ{similar_example['fish_text']}ã€

{history_context}ã€ç¾åœ¨ã®ä¼šè©±ã€‘
å…ç«¥:ã€Œ{user_input}ã€
ãƒ¡ãƒ€ã‚«:
"""
    else:
        # é¡ä¼¼ä¾‹ãŒãªã„å ´åˆã€æˆ¦ç•¥ã‚’çµ„ã¿è¾¼ã‚“ã ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨
        prompt = f"""
ã‚ãªãŸã¯æ°´æ§½ã«ä½ã‚€ã‹ã‚ã„ã„ãƒ¡ãƒ€ã‚«ã€Œã‚·ãƒ­ã¡ã‚ƒã‚“ã€ã§ã™ã€‚å¿œç­”ã¯ã€Œã€ã‚„åå‰ã‚’å«ã‚ãšã€ã‚»ãƒªãƒ•ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
{profile_context}

{response_strategy}

{history_context}å…ç«¥:ã€Œ{user_input}ã€

ä¸Šè¨˜ã®ã€å¿œç­”æˆ¦ç•¥ã€‘ã«åŸºã¥ãã€30æ–‡å­—ä»¥å†…ã§ã€å„ªã—ãå°å­¦ç”Ÿã‚‰ã—ã„å£èª¿ã§ç­”ãˆã¦ãã ã•ã„ã€‚
ãƒ¡ãƒ€ã‚«ã®çŠ¶æ…‹: {medaka_state}

ã‚­ãƒ³ã¡ã‚ƒã‚“:"""
    
    print(f"[å¿œç­”ç”Ÿæˆ] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº†\n{prompt}")

    
    response = await openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ã‚ãªãŸã¯æ°´æ§½ã«ä½ã‚€ã‹ã‚ã„ã„ãƒ¡ãƒ€ã‚«ã€Œã‚·ãƒ­ã¡ã‚ƒã‚“ã€ã§ã™ã€‚å¿œç­”ã¯ã€Œã€ã‚„åå‰ã‚’å«ã‚ãšã€ã‚»ãƒªãƒ•ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"},
            {"role": "user", "content": prompt}
        ],
        temperature=1.0,
        max_tokens=100
    )
    end = time.time()
    reply = response.choices[0].message.content.strip()
    
    print(f"[ãƒ¡ãƒ€ã‚«å¿œç­”ç”Ÿæˆ] æ‰€è¦æ™‚é–“: {end - start:.2f}ç§’")
    print(f"[å¿œç­”ç”Ÿæˆ] ç”Ÿæˆã•ã‚ŒãŸå¿œç­”: '{reply}'")
    
    return reply

class ConversationSession:
    def __init__(self, profile_id: int, child_name: str, first_input: str, medaka_response: str, similar_example: dict, current_stage: str):
        self.profile_id = profile_id
        self.child_name = child_name  # ğŸ”¥ è¿½åŠ : å…ç«¥ã®åå‰
        self.first_child_input = first_input
        self.medaka_response = medaka_response
        self.similar_example = similar_example
        self.current_stage = current_stage
        self.started_at = datetime.now()

    def complete_session(self, second_input: str, assessment_result: tuple):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å®Œäº†"""
        self.second_child_input = second_input
        self.assessment_result = assessment_result[0]
        self.maintain_score = round(float(assessment_result[1]), 3)
        self.upgrade_score = round(float(assessment_result[2]), 3)
        self.confidence_score = round(float(abs(self.upgrade_score - self.maintain_score)), 5)
        
        # ğŸ”¥ conversation_historyã«ã¯ä¿å­˜ã—ãªã„ï¼ˆæ—¢ã«ä¿å­˜æ¸ˆã¿ï¼‰
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã ã‘ãƒ­ã‚°å‡ºåŠ›
        print(f"[ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†] ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ID: {self.profile_id}")
        print(f"[ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†] åˆ¤å®šçµæœ: {self.assessment_result} (ä¿¡é ¼åº¦: {self.confidence_score:.3f})")
        print(f"[ã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº†] ç¾çŠ¶ç¶­æŒã‚¹ã‚³ã‚¢: {self.maintain_score}, æ˜‡æ ¼ã‚¹ã‚³ã‚¢: {self.upgrade_score}")
        
        return None  # DBã«ã¯ä¿å­˜ã—ãªã„

STAGE_PROGRESSION = {
    "stage_1": "stage_2",
    "stage_2": "stage_3",
    "stage_3": "stage_3"
}

# ä¼šè©±åˆ†é¡
async def classify_child_response(
        child_response: str,
        similar_conversation: dict,
        openai_client,
        threshold: float = 0.88
) -> tuple[str, float, float]:
    print(f"[ç™ºé”æ®µéšåˆ¤å®š] å…ç«¥ã®å¿œç­”: '{child_response}'")
    
    resp = await openai_client.embeddings.create(
        input=[child_response],
        model="text-embedding-3-small"
    )
    response_vector = np.array(resp.data[0].embedding)
    
    def convert_to_vector(embedding_data):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚’æ•°å€¤ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›"""
        if isinstance(embedding_data, str):
            import json
            return np.array(json.loads(embedding_data), dtype=float)
            
    maintain_vector = convert_to_vector(similar_conversation['child_reply_1_embedding'])
    upgrade_vector = convert_to_vector(similar_conversation['child_reply_2_embedding'])
    
    def cosine_similarity(v1, v2):
        """ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
        if len(v1) != len(v2):
            raise ValueError(f"ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒãŒä¸€è‡´ã—ã¾ã›ã‚“: {len(v1)} vs {len(v2)}")
        
        norm1 = np.linalg.norm(v1)
        norm2 = np.linalg.norm(v2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return np.dot(v1, v2) / (norm1 * norm2)
    
    maintain_similarity = cosine_similarity(response_vector, maintain_vector)
    upgrade_similarity = cosine_similarity(response_vector, upgrade_vector)
    
    print(f"[ç™ºé”æ®µéšåˆ¤å®š] ç¾çŠ¶ç¶­æŒã¨ã®é¡ä¼¼åº¦: {maintain_similarity:.4f}")
    print(f"[ç™ºé”æ®µéšåˆ¤å®š] æ˜‡æ ¼ã¨ã®é¡ä¼¼åº¦: {upgrade_similarity:.4f}")
    
    if upgrade_similarity > maintain_similarity and upgrade_similarity > threshold:
        result = "æ˜‡æ ¼"
    else:
        result = "ç¾çŠ¶ç¶­æŒ"
    
    confidence = abs(upgrade_similarity - maintain_similarity)
    print(f"[ç™ºé”æ®µéšåˆ¤å®š] çµæœ: {result} (ä¿¡é ¼åº¦: {confidence:.4f})")
    
    return result, maintain_similarity, upgrade_similarity

async def upgrade_by_expression_assessment_async(profile_id: int, current_stage: str, reasoning: str = "") -> dict:
    """
    ç™ºè©±ãƒ¬ãƒ™ãƒ«åˆ¤å®šã«ã‚ˆã‚‹æ®µéšæ˜‡æ ¼ï¼ˆéåŒæœŸç‰ˆï¼‰
    """
    # æ¬¡ã®æ®µéšã‚’å–å¾—
    next_stage = STAGE_PROGRESSION.get(current_stage, current_stage)
    
    # ã™ã§ã«æœ€é«˜æ®µéš
    if next_stage == current_stage:
        print(f"[ç™ºè©±æ˜‡æ ¼] ã™ã§ã«æœ€é«˜æ®µéš: {current_stage}")
        return {
            'success': False,
            'old_stage': current_stage,
            'new_stage': current_stage,
            'reasoning': 'æ—¢ã«æœ€é«˜æ®µéš'
        }
    
    # ğŸ”¥ åŒæœŸå‡¦ç†ã‚’éåŒæœŸã§å®Ÿè¡Œ
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, _upgrade_stage_sync, profile_id, current_stage, next_stage, reasoning)

def _upgrade_stage_sync(profile_id: int, current_stage: str, next_stage: str, reasoning: str) -> dict:
    """åŒæœŸçš„ãªDBæ›´æ–°å‡¦ç†"""
    conn = None
    try:
        conn = get_db_connection()
        if conn is None:
            print(f"âŒ [ç™ºè©±æ˜‡æ ¼] ã‚¨ãƒ©ãƒ¼: DBæ¥ç¶šãªã—")
            return {
                'success': False, 'old_stage': current_stage, 'new_stage': current_stage,
                'reasoning': 'DBæ¥ç¶šã‚¨ãƒ©ãƒ¼'
            }

        with conn.cursor() as cur:
            cur.execute("""
                UPDATE profiles 
                SET development_stage = %s,
                    updated_at = NOW()
                WHERE id = %s
                RETURNING development_stage;
            """, (next_stage, profile_id))
            
            result = cur.fetchone()
            
            if result:
                print(f"ğŸ‰ [ç™ºè©±æ˜‡æ ¼] æˆåŠŸ: {current_stage} â†’ {next_stage}")
                if reasoning:
                    print(f"   ç†ç”±: {reasoning}")
                
                return {
                    'success': True,
                    'old_stage': current_stage,
                    'new_stage': next_stage,
                    'reasoning': reasoning
                }
            else:
                print(f"âš ï¸ [ç™ºè©±æ˜‡æ ¼] ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {
                    'success': False,
                    'old_stage': current_stage,
                    'new_stage': current_stage,
                    'reasoning': 'ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æœªæ¤œå‡º'
                }
                
    except Exception as e:
        print(f"âŒ [ç™ºè©±æ˜‡æ ¼] ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            'success': False,
            'old_stage': current_stage,
            'new_stage': current_stage,
            'reasoning': f'ã‚¨ãƒ©ãƒ¼: {str(e)}'
        }
    finally:
        if conn:
            release_db_connection(conn)

#"""ç™ºé”æ®µéšã‚’1ã¤ä¸Šã’ã‚‹"""
def upgrade_development_stage(profile_id: int, current_stage: str) -> str:
    next_stage = STAGE_PROGRESSION.get(current_stage, current_stage)
    
    if next_stage == current_stage:
        print(f"[ç™ºé”æ®µéš] ã™ã§ã«æœ€é«˜æ®µéš: {current_stage}")
        return current_stage
    
    conn = None
    try:
        conn = get_db_connection()
        if conn is None:
            print(f"[ç™ºé”æ®µéš] æ›´æ–°ã‚¨ãƒ©ãƒ¼: DBæ¥ç¶šãªã—")
            return current_stage

        with conn.cursor() as cur:
            cur.execute("""
                UPDATE profiles 
                SET development_stage = %s,
                    updated_at = NOW()
                WHERE id = %s
                RETURNING development_stage;
            """, (next_stage, profile_id))
            
            result = cur.fetchone()
            
            if result:
                print(f"[ç™ºé”æ®µéš] æ˜‡æ ¼æˆåŠŸ: {current_stage} â†’ {next_stage} (Profile ID: {profile_id})")
                return next_stage
            else:
                print(f"[ç™ºé”æ®µéš] ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: Profile ID {profile_id}")
                return current_stage
                
    except Exception as e:
        print(f"[ç™ºé”æ®µéš] æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        return current_stage
    finally:
        if conn:
            release_db_connection(conn)

# âœ… ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰å…ƒæ°—åº¦ã‚’å—ä¿¡ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.post("/update_health")
async def update_health(request: Request):
    """ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰é€ä¿¡ã•ã‚ŒãŸå…ƒæ°—åº¦ã‚’æ›´æ–°"""
    global latest_health
    
    data = await request.json()
    status = data.get("status", "Unknown")
    avg_speed = data.get("avg_speed", 0)
    score = data.get("score", 0)
    
    latest_health = status
    
    print(f"[å…ƒæ°—åº¦æ›´æ–°] {status} (é€Ÿåº¦: {avg_speed:.2f}px/s, ã‚¹ã‚³ã‚¢: {score})")
    
    return {
        "status": "success",
        "current_health": latest_health
    }

@app.get("/")
async def read_index():
    return FileResponse('index.html', media_type='text/html')

@app.post("/set_current_profile")
async def set_current_profile(request: Request):
    """ç¾åœ¨ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«IDã‚’è¨­å®š"""
    data = await request.json()
    profile_id = data.get("profile_id")
    
    if not profile_id:
        raise HTTPException(400, "profile_id is required")
    
    # ğŸ”¥ å¤‰æ›´å‰ã®å€¤ã‚’ãƒ­ã‚°å‡ºåŠ›
    old_id = CONFIG.PROFILE_ID
    CONFIG.PROFILE_ID = profile_id
    
    print(f"[ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´] {old_id} â†’ {profile_id}")
    
    # ğŸ”¥ ç¢ºèªã®ãŸã‚å–å¾—ã—ã¦ãƒ­ã‚°å‡ºåŠ›
    conn = None
    try:
        conn = get_db_connection()
        if conn:
            with conn.cursor() as cur:
                cur.execute("SELECT name, age FROM profiles WHERE id = %s;", (profile_id,))
                profile = cur.fetchone()
                if profile:
                    print(f"[ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´] é¸æŠ: {profile['name']}ã•ã‚“ ({profile['age']}æ­³)")
        else:
            print("[ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´] DBæ¥ç¶šãŒãªãã€ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    except Exception as e:
        print(f"[/set_current_profile] ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«åã®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    finally:
        if conn:
            release_db_connection(conn)

    return {"success": True, "current_profile_id": CONFIG.PROFILE_ID}

#ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—
@app.get("/profiles")
async def get_profiles():
    """å…¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—"""
    conn = None
    try:
        conn = get_db_connection()
        if conn is None:
            raise HTTPException(status_code=503, detail="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚")
        
        with conn.cursor() as cur:
            cur.execute("SELECT id, name, age, development_stage FROM profiles ORDER BY id;")
            profiles = cur.fetchall()
            return profiles
            
    except Exception as e:
        print(f"[/profiles] ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail="ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        
    finally:
        if conn:
            release_db_connection(conn)

@app.post("/profiles")
async def create_profile(request: Request):
    """æ–°è¦ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
    data = await request.json()
    name = data.get("name")
    age = data.get("age")
    
    conn = None
    try:
        conn = get_db_connection()
        if conn is None:
            raise HTTPException(status_code=503, detail="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚")

        with conn.cursor() as cur:
            cur.execute("""
                INSERT INTO profiles (name, age, development_stage, created_at, updated_at)
                VALUES (%s, %s, 'stage_1', NOW(), NOW())
                RETURNING id, name, age, development_stage;
            """, (name, age))
            new_profile = cur.fetchone()

        raise HTTPException(status_code=500, detail="ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
    finally:
        if conn:
            release_db_connection(conn)
    
def get_proactive_medaka_message(profile):
    """ã“ã®é–¢æ•°ãŒå®Ÿè¡Œã•ã‚ŒãŸå›æ•°ã«å¿œã˜ã¦ãƒ¡ãƒ€ã‚«ã‹ã‚‰ã®ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    profile_id = profile['id']
    call_count = proactive_message_counts[profile_id]
    messages = {
            0: [  # åˆå¯¾é¢ã®å…ç«¥ã«å¯¾ã™ã‚‹è¨€è‘‰
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ"
            ],
            1: [  # è‡ªåˆ†ã®æ„Ÿæƒ…ï¼‹ç›¸æ‰‹ã®æ„Ÿæƒ…ã‚’èã
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ"
            ],
            2: [  # ç›¸æ‰‹ã®æ—¥å¸¸ç”Ÿæ´»ã«é–¢ã™ã‚‹ã“ã¨ï¼ˆæœã«åã‚‰ãªã„ï¼‰
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ"
            ],
            3: [  # ãƒ¡ãƒ€ã‚«è‡ªèº«ãŒå›°ã£ã¦ã„ã‚‹ã“ã¨ã‚’ç›¸è«‡
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ"
            ],
            4: [  # å…ç«¥ã‹ã‚‰ã®è³ªå•ã‚’å—ã‘ä»˜ã‘ã‚‹ãƒ»å¯¾è©±ã‚’å¼•ãå‡ºã™
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ",
                "ã¼ãã­ã€å›ã¨ãŠè©±ã™ã‚‹ã®å¤§å¥½ããªã®ã€œè³ªå•ã—ã¦ã¿ã¦ï¼Ÿ"
            ]
        }
    stage_key = min(call_count, 4)
    
    import random
    message = random.choice(messages[stage_key])

    # æ¬¡å›ã®å‘¼ã³å‡ºã—ã®ãŸã‚ã«ã‚«ã‚¦ãƒ³ãƒˆã‚’å¢—ã‚„ã™
    proactive_message_counts[profile_id] += 1
    
    return message

@app.post("/check_session_status")
async def check_session_status(request: Request):
    data = await request.json()
    profile_id = data.get("profile_id")
    
    if not profile_id:
        raise HTTPException(400, "profile_id is required")
    
    has_active_session = profile_id in active_session
    medaka_proactive_enabled = os.getenv("MEDAKA_PROACTIVE_ENABLED", "true").lower() == "true"
    
    return {
        "has_active_session": has_active_session,
        "conversation_count": len(conversation_history.get(profile_id, [])),
        "proactive_enabled": medaka_proactive_enabled
    }

@app.post("/get_proactive_message")
async def get_proactive_message(request: Request):
    data = await request.json()
    profile_id = data.get("profile_id")
    
    if not profile_id:
        raise HTTPException(400, "profile_id is required")
    
    conn = None
    try:
        conn = get_db_connection()
        if conn is None:
            raise HTTPException(status_code=503, detail="ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚")
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM profiles WHERE id = %s;", (profile_id,))
            profile = cur.fetchone()
            if not profile:
                raise HTTPException(404, "Profile not found")
    except Exception as e:
        print(f"[/get_proactive_message] ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail="ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
    finally:
        if conn:
            release_db_connection(conn)

    # conversation_count ã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆã«ä¸è¦ã«ãªã£ãŸ
    message = get_proactive_medaka_message(profile)
    
    # ğŸ”¥ ä¼šè©±å±¥æ­´ã«è¿½åŠ ï¼ˆãƒ¡ãƒ¢ãƒªå†…ï¼‰
    if profile_id not in conversation_history:
        conversation_history[profile_id] = []
    
    conversation_entry = {
        "child": None,  # ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãªã®ã§å…ç«¥ç™ºè¨€ãªã—
        "medaka": message,
        "timestamp": datetime.now(),
        "similar_example_used": None,
        "similarity_score": None,
        "has_assessment": False,
        "assessment_result": None,
        "session_status": None
    }
    conversation_history[profile_id].append(conversation_entry)
    
    # DBä¿å­˜
    save_conversation_to_db(
        profile_id=profile_id,
        speaker='medaka',
        message=message,
        health_status=latest_health,
        development_stage=profile['development_stage'],
        similar_example_used=False
    )
    
    # TTSç”Ÿæˆï¼ˆä»¥ä¸‹åŒã˜ï¼‰
    async with openai_client.audio.speech.with_streaming_response.create(
        model="tts-1",
        voice="nova",
        instructions="Voice Affect:ã‹ã‚ã„ã‚‰ã—ã„, Tone:é«˜ã„, Pacing:ã‚†ã£ãã‚Š",
        speed=1.0,
        input=message,
        response_format="mp3",
    ) as response:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tts_file:
            async for chunk in response.iter_bytes():
                tts_file.write(chunk)
            tts_path = tts_file.name
    
    return FileResponse(tts_path, media_type="audio/mpeg", filename="proactive_reply.mp3")

# ãƒ‡ãƒãƒƒã‚°ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/conversation_history")
async def get_conversation_history():
    """ç¾åœ¨ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—"""
    if CONFIG.PROFILE_ID in conversation_history:
        return {
            "profile_id": CONFIG.PROFILE_ID,
            "history": list(conversation_history[CONFIG.PROFILE_ID])
        }
    else:
        return {"profile_id": CONFIG.PROFILE_ID, "history": []}

@app.delete("/conversation_history")
async def clear_conversation_history():
    """ç¾åœ¨ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"""
    if CONFIG.PROFILE_ID in conversation_history:
        del conversation_history[CONFIG.PROFILE_ID]
    return {"message": f"History cleared for profile {CONFIG.PROFILE_ID}"}

@app.post("/test_vector_search")
async def test_vector_search(request: Request):
    """ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    data = await request.json()
    user_input = data.get("user_input", "")
    stage = data.get("stage", "stage_1")
    
    result = await find_similar_conversation(user_input, stage)
    return {"query": user_input, "stage": stage, "result": result}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)